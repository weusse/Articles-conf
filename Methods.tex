\section{Methods}\label{Methods}
This work studies the problem of Malaria occurrence prediction and proposes to comparatively evaluate the efficiency of the most popular machine algorithms to tackle this issue. 
To this end, we rely on real data and evaluation metrics, as we detail them next 

\paragraph*{\bf Data collection and preparation.}
In order to carry out  our experiments in a real setting, we have collected two real world datasets about patients living in Senegal. Our first dataset, called DT1, contains medical records about patients living in distinct places in Senegal. and has been collected in 2016 during the \emph{\textquote{Grand Magal of Touba}},  a religious event in Senegal gathering several million of persons every year \cite{Ch17}.   The second dataset, denoted by DT2, contains clinical records about patients living in Diourbel, Thies, and Fatick regions where the prevalence of Malaria is very high. After the collection step, we have conducted data \emph{cleaning}, \emph{transformation}, and \emph{imputation} tasks on the raw datasets in order to deal with noisy information and missing values. We have then proceeded to \emph{feature selection} which enables to only retain the data attributes (or variables) such as \emph{lack of appetite, tiredness, fever, cephalalgia, nausea, arthralgia, digestive disorders, dizziness, chill, myalgia, diarrhea, and abdominal pain} pertaining for our study.
For privacy reasons and certain restrictions in the use of the data, we have ignored patient personal data.
Table \ref{raw_data} summarizes the main statistics of each dataset after preparation and the precision of RDT as well. 
\begin{table}[h]
\resizebox{\textwidth}{!}{
\centering
  \begin{tabular}{cccccccc}
    \toprule
    \multirow{2}{*}{\textbf{Dataset}} &
      \textbf{Variables}&\textbf{Observations}&
      \multicolumn{2}{c}{\textbf{Variables types}}& \multicolumn{2}{c}{\textbf{Classes}} & \textbf{Precision of RDT}\\
    & & & Numeric & Boolean & Malaria & not Malaria \\
    \midrule
    DT1 &16 & 21083  & 2 &  14& 614&20469 & 90.23\% \\
    DT2 & 16 & 5809 & 2 & 14 & 5108&701 & 90.49\% \\
    \bottomrule
  \end{tabular}
  }
  \caption{Main statistics of real datasets DT1 and DT2}\label{raw_data}
\end{table}
We synthetically generated from DT1 and DT2 three additional datasets DT3, DT4 and DT5  respectively obtained by 
\begin{inparaenum}[(i)]
 \item concatenating DT1 and DT2 :
\item selecting $2354$ patients who have been tested negative for Malaria from DT1 and add them to DT2 in order to obtain a balanced dataset; and
\item oversampling DT1 using \emph{SMOTE algorithm} in order to have the same number of individuals in both classes.
\end{inparaenum}

\paragraph*{\bf Machine learning models.}
We have considered and compared the six most popular machine learning approaches \cite{de2018binary,tomar2013survey} which are
Decision Tree (DT)  \cite{Ro05}, Random Forest (RF) \cite{Be01},  Naive Bayes (NB) \cite{Ka17},
Logistic regression (LR) \cite{Ph88}, Support Vector Machine (SVM) \cite{Ev01}, Artificial Neural Network (ANN) \cite{Me19}.
 All of them are supervised learning algorithms, i.e., require a \emph{training phase} with labelled data.

 \paragraph*{\bf Experimentation setting.}
 We have trained and validated each algorithm over every dataset using \emph{stratified-5-fold cross-validation}\footnote{\tiny{\url{https://scikit-learn.org/stable/modules/cross\_validation.html}}} and the same experimentation environment.
 We have relied on ML implementation of the algorithms available with the \emph{Scikit-Learn Python library}.  To evaluate the efficiency of each algorithm,  we finally 
 measured  the \emph{precision}, \emph{recall}, \emph{f1-score}, \emph{AUC}\footnote{\tiny{\url{https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=fr}}}, and
 \emph{specificity} of each algorithm on each dataset. 